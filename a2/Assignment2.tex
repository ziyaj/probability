%Initial setup
\documentclass[11pt]{article}
\title{STAT 302: Assignment 2}
\author{Ziyang Jin \\
\# 34893140}
\date{February 2018}

%Math Packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{breqn}

%General formatting Packages
\usepackage{fancyhdr} %To put headers in
\usepackage{multirow} %for tables
\usepackage{graphicx,graphpap,rotate,geometry,subfigure} 
\usepackage{enumitem} %Permits more customisation of lists than enumerate
\usepackage{tikz} %for textcolor

%Document Layout
%Text positioning
\marginparwidth 0pt %
\marginparsep 0pt  %distance between marginal notes box and main text
\oddsidemargin  0pt
\evensidemargin  0pt
\topmargin   0pt
\textwidth   6.8in %control width of text on 8.5X11 page
\textheight  9.50in %control height of text on 8.5X11 page
\voffset -0.8in

\newcommand{\pr}{\text{Pr}}
\newcommand{\e}{\mathbb{E}}
\newcommand{\var}{\text{Var}}
\newcommand{\sd}{\text{SD}}

%Header of the pages
\pagestyle{fancy}
\lhead{STAT 302}
\rhead{Assignment 2}
\setlength{\headheight}{14pt} %to make room for the header vertically due do squashed height
\fancyhfoffset[R]{0.2in} %to stretch header to match the length of the textwidth.


%=============================
\begin{document}
\maketitle

\begin{enumerate}[label=\textbf{Question \arabic*:},start=1]

%Question 1:
%===================================================
% Adrian's question
\item 
\begin{enumerate}
\item Let Y denote the sum of the values by completing this experiment one time.\\
Let \(X_1\) denote the sum of flipping the coin 1 time. \( X_1 \sim Bin(1, 0.5).\) \\
Let \(X_2\) denote the sum of flipping the coin 2 times. \( X_2 \sim Bin(2, 0.5).\) \\
Let \(X_3\) denote the sum of flipping the coin 3 times. \( X_3 \sim Bin(3, 0.5).\) \\
The probability of drawing ball 1, 2, 3 is equal to 1/3.\\
\begin{equation}
\begin{split}
Pr(Y=0) & = \frac{1}{3} \times (Pr(X_1 = 0) + Pr(X_2 = 0) + Pr(X_3 = 0)) \\
& = \frac{1}{3} \times ({1 \choose 0}(\frac{1}{2})^0(\frac{1}{2})^1 + {2 \choose 0}(\frac{1}{2})^0(\frac{1}{2})^2 + {3 \choose 0}(\frac{1}{2})^0(\frac{1}{2})^3) \\
& = \frac{7}{24} \\
\\
Pr(Y=1) & = \frac{1}{3} \times (Pr(X_1 = 1) + Pr(X_2 = 1) + Pr(X_3 = 1)) \\
& = \frac{1}{3} \times ({1 \choose 1}(\frac{1}{2})^1(\frac{1}{2})^0 + {2 \choose 1}(\frac{1}{2})^1(\frac{1}{2})^1 + {3 \choose 1}(\frac{1}{2})^1(\frac{1}{2})^2) \\
& = \frac{11}{24} \\
\\
Pr(Y=2) & = \frac{1}{3} \times (Pr(X_2 = 2) + Pr(X_3 = 2)) \\
& = \frac{1}{3} \times ({2 \choose 2}(\frac{1}{2})^2(\frac{1}{2})^0 + {3 \choose 2}(\frac{1}{2})^2(\frac{1}{2})^1) \\
& = \frac{5}{24} \\
\\
Pr(Y=3) & = \frac{1}{3} \times Pr(X_3 = 3) \\
& = \frac{1}{3} \times ({3 \choose 3}(\frac{1}{2})^3(\frac{1}{2})^0) \\
& = \frac{1}{24} \\
\end{split}
\end{equation}
Therefore, the probability mass function is:
  \[
    p(y) = \begin{cases}
        7/24, & y = 0\\
        11/24, & y = 1\\
        5/24, & y = 2\\
        1/24 , & y = 3\\
        \end{cases}
  \]

\item Expectation:
\[
\mathbb{E}(Y) = 0 \times \frac{7}{24} + 1 \times \frac{11}{24} + 2 \times \frac{5}{24} + 3 \times \frac{1}{24} = 1
\]
Variance:
\[
Var(Y) = (0 - 1)^2 \times \frac{7}{24} + (1 - 1)^2 \times \frac{11}{24} + (2 - 1)^2 \times \frac{5}{24} + (3 - 1)^2 \times \frac{1}{24} = \frac{2}{3}
\]
Standard Deviation:
\[
SD(Y) = \sqrt{Var(Y)} = \sqrt{\frac{2}{3}}
\]


\item The 3 experiments are independent.\\
Let \(Y_1\) denote the result we get from the first experiment. From (b) we know that:
\[
    p(y_1) = \begin{cases}
        7/24, & y_1 = 0\\
        11/24, & y_1 = 1\\
        5/24, & y_1 = 2\\
        1/24 , & y_1 = 3\\
        \end{cases}
\]
Let \(Y_2\) denote the result we get from the second experiment.\(Y_2 = 2 Y_1\), so
\[
    p(y_2) = \begin{cases}
        7/24, & y_2 = 0\\
        11/24, & y_2 = 2\\
        5/24, & y_2 = 4\\
        1/24 , & y_2 = 6\\
        \end{cases}
\]
Let \(Y_3\) denote the result we get from the third experiment.\(Y_3 = 3 Y_1\), so
\[
    p(y_3) = \begin{cases}
        7/24, & y_3 = 0\\
        11/24, & y_3 = 3\\
        5/24, & y_3 = 6\\
        1/24 , & y_3 = 9\\
        \end{cases}
\]
Let Y denote the total sum observed after completing this three part experiment, so the \textit{pmf} of Y is:
\[
    p(y) = \begin{cases}
        \frac{343}{24^3}, & y = 0\\
        \frac{539}{24^3}, & y = 1\\
        \frac{784}{24^3}, & y = 2\\
        \frac{1435}{24^3} , & y = 3\\
        \frac{1477}{24^3}, & y = 4\\
        \frac{1694}{24^3}, & y = 5\\
        \frac{1877}{24^3}, & y = 6\\
        \frac{1487}{24^3}, & y = 7\\
        \frac{1321}{24^3}, & y = 8\\
        \frac{1048}{24^3}, & y = 9\\
        \frac{703}{24^3}, & y = 10\\
        \frac{497}{24^3}, & y = 11\\
        \frac{299}{24^3}, & y. = 12\\
        \frac{170}{24^3}, & y = 13\\
        \frac{91}{24^3}, & y = 14\\
        \frac{37}{24^3}, & y = 15\\
        \frac{16}{24^3}, & y = 16\\
        \frac{5}{24^3}, & y = 17\\
        \frac{1}{24^3}, & y = 18\\
        \end{cases}
\]
So the expectation can be computed as sum of \( E(Y_1), E(Y_2), E(Y_3) \):
\[
\mathbb{E}(Y) = \mathbb{E}(Y_1 + Y_2 + Y_3) = 1 + 2 + 3 = 6
\]
So the standard deviation for the total sum is:
\[
Var(Y) = \sum (y-6)^2\ p(y) = \frac{116480}{13824} = \frac{455}{54} = 8.4259
\]
\[
SD(Y) = \sqrt{Var(Y)} = 2.9027
\] 
\end{enumerate}



%Question 2:
%===================================================
% Julian's question
\item
\begin{enumerate}
  \item 
  \begin{enumerate}
    \item The probability of picking the first type of coin is 7/10. Let \( X_1 \) be the number of trials Peter needs to have 3 heads when he picks the first type of coin, then \( X_1 \sim NegBin(3, 0.5) \). \\
    \\
    The probability of picking the first type of coin is 3/10. Let \( X_2 \) be the number of trials Peter needs to have 3 heads when he picks the first type of coin, then \( X_2 \sim NegBin(3, 0.7) \). \\
    \\
    Let X denote the number of trials Peter needs to get 3 heads after he randomly picks a coin. Then the probability mass function is:
\[
p(x) = 0.7 \cdot p(x_1) + 0.3 \cdot p(x_2) =\frac{7}{10} {x-1 \choose 2} 0.5^3 0.5^{x-3} + \frac{3}{10} {x-1 \choose 2} 0.7^3 0.3^{x-3} 
\]
Therefore,
\[
p(x) = 0.7{x-1 \choose 2}(0.5^x + 0.7^2 \cdot 0.3^{x-2}), \ x = 3, 4, 5, ...
\]


    \item The expectation is:
\[
\mathbb{E}(X) = \sum_x x \cdot p(x) = 0.7 \  \mathbb{E}(X_1) + 0.3 \ \mathbb{E}(X_2) = 0.7 \times \frac{3}{0.5} + 0.3 \times \frac{3}{0.7} = \frac{192}{35} = 5.486
\]
The variance is:
\[
Var(X) = \mathbb{E}(X^2) - [\mathbb{E}(X)]^2 = 0.7 \ \mathbb{E}(X_1^2) + 0.3 \ \mathbb{E}(X_2^2) - [\mathbb{E}(X)]^2
\]
(1) Let's compute \(\mathbb{E}(X_1^2) \)
\[
\mathbb{E}(X_1^2) = \sum_x x^2 \ {x-1 \choose 2} 0.5^x = 3 \sum_x x {x \choose 3} 0.5^x
\]
let \( y = x + 1 \), we have 
\[
\mathbb{E}(X_1^2) = 3 \sum_y (y-1) \ {y-1 \choose 3} 0.5^{y-1} = 6 [\sum_y y {y-1 \choose 3} 0.5^y - \sum {y-1 \choose 3} 0.5^y]
\]
suppose we have \( Y_1 \sim NegBin(4, 0.5) \)
\[
\mathbb{E}(X_1^2) = 6 [\mathbb{E}(Y_1) - 1] = 6 (\frac{4}{0.5} - 1) = 42
\]
(2) Let's compute \(\mathbb{E}(X_2^2) \)
\[
\mathbb{E}(X_2^2) = \sum_x x^2 \ {x-1 \choose 2} 0.7^3 \ 0.3^{x-3} = \frac{30}{7} \sum_x x {x \choose 3} 0.7^4 \ 0.3^{x-3}
\]
let \( y = x + 1 \), we have 
\[
\mathbb{E}(X_2^2) = \frac{30}{7} \sum_y (y-1) {y-1 \choose 3} 0.7^4 \ 0.3^{y-4} = \frac{30}{7} (\sum_y y {y-1 \choose 3} 0.7^4 \ 0.3^{y-4} - \sum_y {y-1 \choose 3} 0.7^4 \ 0.3^{y-4})
\]
suppose we have \( Y_2 \sim NegBin(4, 0.7) \)
\[
\mathbb{E}(X_2^2) = \frac{30}{7} [\mathbb{E}(Y_2) - 1] = \frac{30}{7} (\frac{4}{0.7} - 1) = \frac{990}{49}
\]
(3) Finally, we compute the variance:
\[
Var(X) = \mathbb{E}(X^2) - [\mathbb{E}(X)]^2 = 0.7 \times 42 + 0.3 \times \frac{990}{49} - (\frac{192}{35})^2 = \frac{6576}{1225} = 5.368
\]


  \end{enumerate}

  \item Let Y denote the number of tosses needed to obtain 3 heads. \( Y \sim NegBin(3, p) \). \\
Let \( X_1 \) denote the event that Peter picks the first type of coin. \(Pr(X_1) = 0.7, \  p = 0.5.\) \\
Let \( X_2 \) denote the event that Peter picks the second type of coin. \( Pr(X_2) = 0.3, \ p = 0.7.\) \\
\[
Pr(Y=6 \ | X_1) = {5 \choose 2} 0.5^3 \ (1-0.5)^{6-3} = \frac{5}{32} = 0.15625
\]
\[
Pr(Y=6 \ | X_2) = {5 \choose 2} 0.7^3 \ (1-0.7)^{6-3} = \frac{9261}{100000} = 0.09261
\]
According to the PMF obtained in (a),
\[
Pr(Y = 6) = 0.7 {5 \choose 2} ( 0.5^6 + 0.7^2 \cdot 0.3^4 ) = \frac{68579}{100000} = 0.137158
\]
The question is asking about \( Pr(X_1 \ | Y = 6) \). According to \textit{Bayes' Theorem}:
\[
Pr(X_1 \ | Y = 6) = \frac{Pr(Y = 6 \  | X_1) Pr(X_1)}{Pr(Y = 6)} = \frac{0.15625 \times 0.7}{0.137158} = \frac{109375}{137158} = 0.797438
\]


  \item Let Y denote the number of trials until the first head is obtained. \( Y \sim Geom(p) \).\\
Let W denote the event that is takes at most 4 tosses to obtain the first head.\\
Then we have \( Pr(W) = Pr(Y = 1) + Pr(Y = 2) + Pr(Y = 3) + Pr(Y = 4)\). \\
Let \( X_1 \) denote the event that Peter picks the first type of coin. \(Pr(X_1) = 0.7, \  p = 0.5.\) \\
%Let \( X_2 \) denote the event that Peter picks the second type of coin. \( Pr(X_2) = 0.3, \ p = 0.7.\) \\
\[
Pr(W | X_1) = (1-0.5)^{1-1} \ 0.5 + (1-0.5)^{2-1}\ 0.5 + (1-0.5)^{3-1} \ 0.5 + (1 - 0.5)^{4-1} \ 0.5 = \frac{15}{16} = 0.9375
\]
%\[
%Pr(W | X_2) = (1-0.7)^{1-1} \ 0.7 + (1-0.7)^{2-1}\ 0.7 + (1-0.7)^{3-1} \ 0.7 + (1 - 0.7)^{4-1} \ 0.7 = \frac{9919}{10000} = 0.9919
%\]
%Total probability:
%\[
%Pr(W) = 0.7 \times 0.9375 + 0.3 \times 0.9919 = 0.65625 + 0.29757 = 0.95382
%\]
So the probability that Peter correctly identifiers a randomly chosen coin is:
\[
Pr(W \cap X_1) = Pr(W | X_1) Pr(X_1) = 0.9375 \times 0.7 = 0.65625
\]
\end{enumerate}




%Question 3:
%===================================================

\item 
\begin{enumerate}
  \item A is a Hypergeometric random variable with parameters N = 20, n = 10, m = 12. \\
So \( A \sim Hypergeom(20, 10, 12) \).\\
\[
Pr(5 \leq A \leq 7) = Pr(A = 5) + Pr(A = 6) + Pr(A = 7)
\]
\[
= \frac{{12 \choose 5} {8 \choose 5} }{{20 \choose 10}} + \frac{{12 \choose 6} {8 \choose 4}}{{20 \choose 10}} + \frac{{12 \choose 7} {8 \choose 3}}{{20 \choose 10}} = \frac{153384}{184756} = 0.8301976661
\]

B is a Binomial random variable with parameters n = 10, p = 12/20 = 0.6.\\
So \( B \sim Bin(10, 0.6) \). \\
\[
Pr(5 \leq B \leq 7) = Pr(B = 5) + Pr(B = 6) + Pr(B = 7) 
\]
\[
= {10 \choose 5} 0.6^5 \ 0.4^5 + {10 \choose 6} 0.6^6 \ 0.4^4 + {10 \choose 7} 0.6^7 \ 0.4^3 = 0.6664716288
\]

A's sampling scheme seems better because there is no "strengthen" of repeated opinion in the final result, so A's scheme can possibly represent a larger number of students than B does.\\

  \item A is a Hypergeometric random variable with parameters N = 20000, n = 1000, m = \( 20000 \times 60\% \)= 12000. \\
So \( A \sim Hypergeom(20000, 1000, 12000) \).\\
\[
\mathbb{E}(A) = \frac{ n m }{N} = \frac{1000 \times 12000}{20000} = 600
\]

B is a Binomial random variable with parameters n = 1000, p = 60\% = 0.6.\\
So \( B \sim Bin(1000, 0.6) \). \\
\[
\mathbb{E}(B) = np = 1000 \times 0.6 = 600
\]

  \item 
  
\[
Pr(\mathbb{E}(A) - 15 \leq A \leq \mathbb{E}(A) + 15) = \sum_{k = 585}^{615} \frac{{12000 \choose k} {8000 \choose n-k}}{{20000 \choose 1000}} = 1
\]
\[
= \texttt{phyper(615, 12000, 8000, 1000) - phyper(584, 12000, 8000, 1000)} = 0.695355
\]

\[
Pr(\mathbb{E}(B) - 15 \leq B \leq \mathbb{E}(B) + 15) = \sum_{k = 585}^{615} {1000 \choose k} 0.6^k 0.4^{1000-k}
\]
\[
= \texttt{pbinom(615, size=1000, prob=0.6) - pbinom(584, size=1000, prob=0.6)} = 0.6829448
\]
\[
\texttt{Diff}_a = 0.8301976661 - 0.6664716288 = 0.1637260373
\]
\[
\texttt{Diff}_c = 0.695355 - 0.6829448 = 0.0124102
\]
There difference in probabilities found in (c) is significantly smaller than the difference in probabilities found in (a).
Therefore, I do not prefer one sampling scheme to the other. When the sample space gets bigger and bigger, the resulting probabilities chosen between binomial and hypergeometric gets closer and closer. If the sample space is large enough, the difference in resulting probabilities becomes insignificant.

  \item {\em [Optional bonus question]} 
\textbf{Proof:}\\
\begin{equation}
\begin{split}
\lim_{N\rightarrow\infty} \frac { {m \choose x}{N-m \choose n-x}}{ {N\choose n}} & = \lim_{N\rightarrow\infty} \frac { \frac{m!}{x!(m-x)!} \cdot \frac{(N-m)!}{(n-x)!(N-m-(n-x))!}}{ \frac{N!}{n!(N-n)!} } \\
& = \lim_{N\rightarrow\infty} \frac{n!}{x!(n-x)!} \cdot \frac{m! (N-m)! (N-n)!}{(m-x)! (N-m - (n-x))! N!} \\
& = \frac{n!}{x!(n-x)!}  \lim_{N\rightarrow\infty} \frac{(m-x+1)...m \cdot (N-m-(n-x)+1)...(N-m)}{(N-n+1)...N} \\
& = \frac{n!}{x!(n-x)!}  (\frac{m}{N})^x (\frac{N-m}{N})^{n-x} \\
& = {n \choose x} p^x (1-p)^{n-x}
\end{split}
\end{equation}

line 1 just expand the combinations. \\
line 2 rearranges the division and pulls out  $\frac{n!}{x!(n-x)!}$ \\
line 3 cancels same items in $m!$ with $(m-x)!$,  $(N-m)!$ with $(N-m-(n-x))!$, $N!$ with $(N-n)!$. \\
line 4, notice that there are $x$ items in $(m-x+1)...m$, and there are $(n-x)$ items in $(N-m-(n-x)+1)...(N-m)$, and there are $n$ items in $(N-n+1)...N$, also $n = x + n-x$. So when we take the limit, we can replace all items in $(m-x+1)...m$ with $m^x$, $(N-m-(n-x)+1)...(N-m)$ with $(N-m)^{n-x}$, $(N-n+1)...N$ with $N^x N^{n-x}$ because they are asymptotically equivalent when taking the limit. Therefore we get the result in line 4. \\
line 5, notice that expression in line 4 is just the expanded form of line 5, after replacing $\frac{m}{N}$ with $p$.\\
Q.E.D.

\end{enumerate}




\vspace*{3mm}

%Question 4:
\item 
\begin{enumerate}
\item
Let X be the number of cormorant pairs appearing at the colony. \( X \sim Poisson(20) \) \\
\[
p(x) = \frac{20^x e^{-20}}{x!}
\]
We would like to know the value of k, such that:
\[
p(0) + p(1) + p(2) + ... +  p(k) \geq 90\%
\]
\[
\frac{20^0 e^{-20}}{0!} + \frac{20^1 e^{-20}}{1!} + \frac{20^2 e^{-20}}{2!} + ... + \frac{20^k e^{-20}}{k!} \geq 90\%
\]
Using R, we notice that \texttt{ppois(25, lambda=20) = 0.887815}, and \texttt{ppois(26, lambda=20) = 0.9221132}. Therefore $k = 26$. \\
So the expected number of the team size is: $26/5 = 5.2$ member.\\

\item 
3 members can observe $3 \times 5 = 15$ cormorant pairs.\\
Let X be the number of cormorant pairs appearing at the colony. \( X \sim Poisson(20 \times 2) \) \\
\[
p(x) = \frac{40^x e^{-40}}{x!}
\]
The probability that 3 members can observe all the cormorant pairs at any one time is:
\[
p(0) + p(1) + p(2) + ... + p(15) = \sum_{k=0}^{15} \frac{40^k e^{-40}}{k!} = \texttt{ppois(15, lambda=40)} = 5.463981 \times 10^{-6}
\]

\end{enumerate}



% Question 5:
%===================================================

\item 
\begin{enumerate}
  \item 
\[
\int_{-\infty}^{\infty} f(x) dx = \int_{0}^{\pi} cx sin(x) dx = 1
\]
\[
 \int_{0}^{\pi} cx sin(x) dx = c( (x \cdot -cos(x))|_{0}^{\pi} - \int_{0}^{\pi} -cos(x)dx ) = c (\pi - 0 + sin(x) |_{0}^{\pi}) = c \pi
\]
\[
c \pi = 1 \Rightarrow c = \frac{1}{\pi}
\]

  \item 
\[
 \int \frac{1}{\pi} x sin(x) dx = \frac{1}{\pi}( -xcos(x) + \int cos(x)dx ) = \frac{1}{\pi} (-xcos(x) + sin(x) + C)
\]
In this case $C = 0$. Therefore, the CDF of E is:
\[
F(x) = \begin{cases}
        0, & x \leq 0\\
        \frac{1}{\pi} (-xcos(x) + sin(x)), & 0 < x < \pi\\
        1, & x \ge \pi\\
        \end{cases}
\]


  \item 
\[
p = Pr(X > 3) = 1 - Pr(X \leq 3) = 1 - \frac{1}{\pi}(-3 cos(3) + sin(3)) = 0.00970690954 \approx 0.01
\]
Let Y denote the number of samples we take until we find the first with an energy intake exceeding 3 kilocalories. \\
\[
Y \sim Geom(0.01)
\]
The probability that we have to sample more than 10 trees is:
\[
Pr(Y > 10) = 1 - (\sum_{k=1}^{10} Pr(Y = k) ) = 1 - (\sum_{k=1}^{10} 0.99^{k-1} 0.01) = \texttt{1 - pgeom(10, 0.01)} = 0.8953383
\]



\end{enumerate}

\end{enumerate}
\end{document}